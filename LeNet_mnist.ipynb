{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Library Load  #We are gonna use Functional Keras\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Conv2D, BatchNormalization, MaxPooling2D, Flatten, Dropout, Input, AveragePooling2D\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "#Dataset Load\n",
    "\n",
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "print(x_train.shape) # Examples, H, W, Depth(rgb=3)\n",
    "print(y_train.shape) # its not one hot encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "#Data Preperation\n",
    "\n",
    "img_H = x_train.shape[1]\n",
    "img_W = x_train.shape[2]\n",
    "depth = 1\n",
    "\n",
    "input_shape = (img_H, img_W, depth)\n",
    "\n",
    "# we change our image type to float32 #needed in order to normalize later\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# Getting our date in the right 'shape' needed for Keras\n",
    "# We need to add a 4th dimenion to our date thereby changing our\n",
    "# Our original image shape of (60000,28,28) to (60000,28,28,1)\n",
    "x_train = x_train.reshape(x_train.shape[0], img_H, img_W, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_H, img_W, 1)\n",
    "\n",
    "# image normalization max 255 becomes 1\n",
    "x_train = x_train/255\n",
    "x_test = x_test/255\n",
    "\n",
    "print(x_train.shape)\n",
    "\n",
    "#one hot encoding\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "print(y_train.shape) #10 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "784\n"
     ]
    }
   ],
   "source": [
    "#Extra information\n",
    "\n",
    "no_classes = y_train.shape[1]\n",
    "no_pixels= img_W*img_H*depth #in one image\n",
    "\n",
    "print(no_classes)\n",
    "print(no_pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 6)         156       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 24, 24, 6)         0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 12, 12, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 16)          2416      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 8, 8, 16)          0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_2 (Average (None, 4, 4, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 1, 1, 120)         30840     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 1, 1, 120)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 84)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                850       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 44,426\n",
      "Trainable params: 44,426\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Model Architecture #original LeNet had tanh  #lenet was designed for a 32x32 input we had a 28x28 #padding is valid in lenet\n",
    "\n",
    "i = Input(shape=(img_H, img_W, depth)) #We define the input shape #height x width X depth #We could have used input_shape\n",
    "\n",
    "#Convolutional Layers\n",
    "x = Conv2D(filters=6, kernel_size=(5,5), padding=\"valid\")(i) #default padding is valid\n",
    "#x = BatchNormalization()(x) #Batch Norm is added after the convolution operation and before the  ReLU\n",
    "x = Activation(\"tanh\")(x)\n",
    "x = AveragePooling2D(padding=\"same\")(x) #default values are strides = 2 and filter dimensions = 2 \n",
    "#28x28x1 --> 24x24x6 --> 12x12x6\n",
    "\n",
    "x = Conv2D(filters=16, kernel_size=(5,5), padding=\"valid\")(x) #default padding is valid\n",
    "#x = BatchNormalization()(x) #Batch Norm is added after the convolution operation and before the  ReLU\n",
    "x = Activation(\"tanh\")(x)\n",
    "x = AveragePooling2D(padding=\"same\")(x) #default values are strides = 2 and filter dimensions = 2 \n",
    "#12x12x6 --> 8x8x16 --> 4x4x16\n",
    "\n",
    "x = Conv2D(filters=120, kernel_size=(4,4), padding=\"valid\")(x) #default padding is valid\n",
    "#x = BatchNormalization()(x) #Batch Norm is added after the convolution operation and before the  ReLU\n",
    "x = Activation(\"tanh\")(x)\n",
    "#x = MaxPooling2D(padding=\"valid\")(x) #default values are strides = 2 and filter dimensions = 2 \n",
    "#4x4x16 --> 1x1x120 \n",
    "#If our kernel size is the same as our feature map size the result is 1x1 (f-k)/s +1\n",
    "\n",
    "#Flattening\n",
    "x = Flatten()(x) #1x1x120=120 features  dim = (-1,120)\n",
    "\n",
    "#Fully Connected Layers\n",
    "#x = Dense(units=400)(x) #128 neurons\n",
    "#x = Activation('relu')(x)\n",
    "#x = Dropout(0.5)(x)#Dropout probability to drop a neuron #Dropout is added after the activation\n",
    "x = Dense(units=84)(x) #128 neurons\n",
    "x = Activation('tanh')(x)\n",
    "#x = Dropout(0.5)(x)#Dropout probability to drop a neuron #Dropout is added after the activation\n",
    "x = Dense(units=no_classes)(x)#Where k is the no classes\n",
    "x = Activation('softmax')(x)#Here on the contrary with tensorflow we have to manually add the softmax layer\n",
    "\n",
    "\n",
    "#Compile the model\n",
    "model = Model(inputs = i, outputs=x ) #we need to define the input and the output of the model\n",
    "\n",
    "#Model Architecture Visualization\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss Function, Optimizer and metrics\n",
    "\n",
    "model.compile(loss = \"categorical_crossentropy\",\n",
    "             optimizer = \"adam\",\n",
    "             metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 14s 234us/step - loss: 0.2451 - acc: 0.9269 - val_loss: 0.1401 - val_acc: 0.9570\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 0.0963 - acc: 0.9700 - val_loss: 0.0687 - val_acc: 0.9780\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 10s 162us/step - loss: 0.0649 - acc: 0.9802 - val_loss: 0.0612 - val_acc: 0.9801\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 0.0501 - acc: 0.9844 - val_loss: 0.0505 - val_acc: 0.9839\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 0.0411 - acc: 0.9873 - val_loss: 0.0565 - val_acc: 0.9822\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.0335 - acc: 0.9891 - val_loss: 0.0467 - val_acc: 0.9850\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.0282 - acc: 0.9909 - val_loss: 0.0454 - val_acc: 0.9855\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 0.0237 - acc: 0.9926 - val_loss: 0.0461 - val_acc: 0.9865\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.0205 - acc: 0.9934 - val_loss: 0.0457 - val_acc: 0.9857\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 0.0182 - acc: 0.9940 - val_loss: 0.0483 - val_acc: 0.9855\n"
     ]
    }
   ],
   "source": [
    "#Training\n",
    "\n",
    "#keras could also split the data for us using  validation split option (=0.2)\n",
    "r=model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10, batch_size = 32) #default verbose is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved\n"
     ]
    }
   ],
   "source": [
    "#Model saving\n",
    "\n",
    "model.save(\"Keras_LeNet5_mnist.h5\")\n",
    "print(\"Model Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
